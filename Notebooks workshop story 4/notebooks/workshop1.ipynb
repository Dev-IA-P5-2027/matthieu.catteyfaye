{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66dce97f",
   "metadata": {},
   "source": [
    "Step 1: Separate By Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e36c3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9001a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[3.393533211, 2.331273381, 0]\n",
      "[3.110073483, 1.781539638, 0]\n",
      "[1.343808831, 3.368360954, 0]\n",
      "[3.582294042, 4.67917911, 0]\n",
      "[2.280362439, 2.866990263, 0]\n",
      "1\n",
      "[7.423436942, 4.696522875, 1]\n",
      "[5.745051997, 3.533989803, 1]\n",
      "[9.172168622, 2.511101045, 1]\n",
      "[7.792783481, 3.424088941, 1]\n",
      "[7.939820817, 0.791637231, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test separating data by class\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "separated = separate_by_class(dataset)\n",
    "for label in separated:\n",
    "\tprint(label)\n",
    "\tfor row in separated[label]:\n",
    "\t\tprint(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9978d9b",
   "metadata": {},
   "source": [
    "Step 2: Summarize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "641d408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f0e1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "\treturn sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eac6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "\tdel(summaries[-1])\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74561eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.1783333865, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_dataset(dataset)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a60e20",
   "metadata": {},
   "source": [
    "Step 3: Summarize Data By Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ef0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "\tseparated = separate_by_class(dataset)\n",
    "\tsummaries = dict()\n",
    "\tfor class_value, rows in separated.items():\n",
    "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f827d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2.7420144012, 0.9265683289298018, 5)\n",
      "(3.0054686692, 1.1073295894898725, 5)\n",
      "1\n",
      "(7.6146523718, 1.2344321550313704, 5)\n",
      "(2.9914679790000003, 1.4541931384601618, 5)\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_by_class(dataset)\n",
    "for label in summary:\n",
    "\tprint(label)\n",
    "\tfor row in summary[label]:\n",
    "\t\tprint(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92f7a6",
   "metadata": {},
   "source": [
    "Step 4: Gaussian Probability Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee7766a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3989422804014327\n",
      "0.24197072451914337\n",
      "0.24197072451914337\n"
     ]
    }
   ],
   "source": [
    "# Example of Gaussian PDF\n",
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "# Test Gaussian PDF\n",
    "print(calculate_probability(1.0, 1.0, 1.0))\n",
    "print(calculate_probability(2.0, 1.0, 1.0))\n",
    "print(calculate_probability(0.0, 1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa63d0",
   "metadata": {},
   "source": [
    "Step 5: Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd2f1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "\tprobabilities = dict()\n",
    "\tfor class_value, class_summaries in summaries.items():\n",
    "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "\t\tfor i in range(len(class_summaries)):\n",
    "\t\t\tmean, stdev, count = class_summaries[i]\n",
    "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "\treturn probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee76d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"
     ]
    }
   ],
   "source": [
    "summaries = summarize_by_class(dataset)\n",
    "probabilities = calculate_class_probabilities(summaries, dataset[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94332e41",
   "metadata": {},
   "source": [
    "Iris Flower Species Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41f14996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\n",
      "Mean Accuracy: 95.333%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes On The Iris Dataset\n",
    "from csv import reader\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tnext(csv_reader, None)  # saute l’en-tête\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor _ in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "\treturn sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "\tdel(summaries[-1])\n",
    "\treturn summaries\n",
    "\n",
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "\tseparated = separate_by_class(dataset)\n",
    "\tsummaries = dict()\n",
    "\tfor class_value, rows in separated.items():\n",
    "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
    "\treturn summaries\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "\tprobabilities = dict()\n",
    "\tfor class_value, class_summaries in summaries.items():\n",
    "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "\t\tfor i in range(len(class_summaries)):\n",
    "\t\t\tmean, stdev, _ = class_summaries[i]\n",
    "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "\treturn probabilities\n",
    "\n",
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
    "\tbest_label, best_prob = None, -1\n",
    "\tfor class_value, probability in probabilities.items():\n",
    "\t\tif best_label is None or probability > best_prob:\n",
    "\t\t\tbest_prob = probability\n",
    "\t\t\tbest_label = class_value\n",
    "\treturn best_label\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "\tsummarize = summarize_by_class(train)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict(summarize, row)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test Naive Bayes on Iris Dataset\n",
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(f\"../data/{filename}\")\n",
    "for i in range(len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfa1a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = summarize_by_class(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1943edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 2, Actual: 2\n",
      "Accuracy: 96.000%\n"
     ]
    }
   ],
   "source": [
    "# Predict for a single row\n",
    "# -----------------------------\n",
    "# Exemple : prédire la première ligne du dataset\n",
    "row = dataset[0][:-1]  # retire la colonne de classe\n",
    "label = predict(model, row)\n",
    "print(f\"Predicted: {label}, Actual: {dataset[0][-1]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Predict for multiple rows\n",
    "# -----------------------------\n",
    "test_rows = [r[:-1] for r in dataset]  # retirer la colonne de classe\n",
    "predictions = [predict(model, r) for r in test_rows]\n",
    "\n",
    "# Comparer avec les vraies classes\n",
    "actual = [r[-1] for r in dataset]\n",
    "\n",
    "# Calculer précision\n",
    "accuracy = accuracy_metric(actual, predictions)\n",
    "print(f\"Accuracy: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "021ab300",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# predict the label\u001b[39;00m\n\u001b[32m      2\u001b[39m row = dataset[\u001b[32m0\u001b[39m][-\u001b[32m1\u001b[39m] \u001b[38;5;66;03m# retire la dernière colonne\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m label = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(summaries, row)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(summaries, row):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \tprobabilities = \u001b[43mcalculate_class_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \tbest_label, best_prob = \u001b[38;5;28;01mNone\u001b[39;00m, -\u001b[32m1\u001b[39m\n\u001b[32m    132\u001b[39m \t\u001b[38;5;28;01mfor\u001b[39;00m class_value, probability \u001b[38;5;129;01min\u001b[39;00m probabilities.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mcalculate_class_probabilities\u001b[39m\u001b[34m(summaries, row)\u001b[39m\n\u001b[32m    123\u001b[39m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_summaries)):\n\u001b[32m    124\u001b[39m \t\tmean, stdev, _ = class_summaries[i]\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \t\tprobabilities[class_value] *= calculate_probability(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, mean, stdev)\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# predict the label\n",
    "row = dataset[0][-1] # retire la dernière colonne\n",
    "label = predict(model, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97ec3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\t\tprint('[%s] => %d' % (value, i))\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca02b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "# define a new record\n",
    "row = [5.7,2.9,4.2,1.3]\n",
    "# predict the label\n",
    "label = predict(model, row)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
